# KnowledgeCore Engine Environment Variables
# 复制此文件为 .env 并填入您的配置
# 
# 注意：所有环境变量使用 KCE_ 前缀以避免与其他项目冲突

# ========== LLM 配置 ==========
# 选择一个 LLM 提供商并配置相应的 API Key

# DeepSeek (推荐，成本低效果好)
KCE_DEEPSEEK_API_KEY=your_deepseek_api_key_here

# 通义千问 (阿里云 DashScope)
KCE_DASHSCOPE_API_KEY=your_dashscope_api_key_here

# OpenAI (可选)
KCE_OPENAI_API_KEY=your_openai_api_key_here

# 默认 LLM 配置
KCE_LLM_PROVIDER=deepseek  # 可选: deepseek, qwen, openai
KCE_LLM_MODEL=deepseek-chat  # 或 qwen2.5-72b-instruct, gpt-4-turbo-preview

# ========== 嵌入模型配置 ==========
# 默认使用通义千问的嵌入模型
KCE_EMBEDDING_PROVIDER=dashscope  # 可选: dashscope, openai
KCE_EMBEDDING_MODEL=text-embedding-v3

# ========== 文档解析配置 ==========
# LlamaParse API Key (可选，提供1000次/天免费额度)
KCE_LLAMA_CLOUD_API_KEY=your_llama_parse_key_here

# ========== 向量数据库配置 ==========
# ChromaDB (默认，无需额外配置)
KCE_VECTOR_STORE_PROVIDER=chromadb
KCE_CHROMA_PERSIST_DIRECTORY=./data/chroma_db
KCE_CHROMA_COLLECTION_NAME=knowledge_core

# Pinecone (可选)
# KCE_PINECONE_API_KEY=your_pinecone_api_key_here
# KCE_PINECONE_ENVIRONMENT=us-east-1-aws
# KCE_PINECONE_INDEX_NAME=knowledge-core

# Weaviate (可选)
# KCE_WEAVIATE_URL=http://localhost:8080
# KCE_WEAVIATE_API_KEY=your_weaviate_api_key_here

# ========== 重排序模型配置 ==========
# 使用 HuggingFace 模型进行重排序
KCE_RERANKER_MODEL=gte-rerank

# ========== API 服务器配置 ==========
KCE_API_HOST=0.0.0.0
KCE_API_PORT=8000
KCE_API_RELOAD=true

# ========== 日志配置 ==========
KCE_LOG_LEVEL=INFO  # DEBUG, INFO, WARNING, ERROR
KCE_LOG_FILE=./logs/knowledge_core.log

# ========== 性能配置 ==========
KCE_RETRIEVAL_TOP_K=20
KCE_RERANK_TOP_K=5
KCE_CHUNK_SIZE=1024
KCE_CHUNK_OVERLAP=200

# ========== 缓存配置 ==========
KCE_ENABLE_CACHE=true
KCE_CACHE_TTL=86400  # 24 hours
KCE_CACHE_DIR=./data/cache

# ========== 其他配置 ==========
# 开发模式
KCE_DEBUG=false