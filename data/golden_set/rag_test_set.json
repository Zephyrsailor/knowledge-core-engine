{
  "metadata": {
    "name": "RAG系统黄金测试集",
    "version": "1.0",
    "description": "用于评估RAG系统性能的标准测试集",
    "created_date": "2024-07-16",
    "language": "zh",
    "domain": "RAG技术"
  },
  "test_cases": [
    {
      "id": "tc_001",
      "category": "概念理解",
      "question": "什么是RAG技术？请解释其核心原理。",
      "ground_truth": "RAG（Retrieval-Augmented Generation）是一种结合了信息检索和文本生成的AI技术。其核心原理是：首先从知识库中检索与查询相关的文档片段，然后将这些检索到的信息作为上下文，输入到语言模型中生成更准确、更可靠的答案。这种方法可以有效减少AI幻觉，提供可追溯的信息来源。",
      "expected_keywords": ["检索", "生成", "知识库", "上下文", "幻觉", "可追溯"],
      "difficulty": "easy"
    },
    {
      "id": "tc_002",
      "category": "系统架构",
      "question": "RAG系统的主要组件有哪些？各组件的作用是什么？",
      "ground_truth": "RAG系统的主要组件包括：1）文档解析器：将各种格式的文档转换为统一格式；2）文本分块器：将长文档分割成适合检索的片段；3）嵌入模型：将文本转换为向量表示；4）向量数据库：存储和索引文档向量；5）检索器：根据查询找到相关文档；6）重排序器：对检索结果进行精排；7）生成模型：基于检索内容生成答案。",
      "expected_keywords": ["文档解析", "分块", "嵌入", "向量数据库", "检索", "重排序", "生成"],
      "difficulty": "medium"
    },
    {
      "id": "tc_003",
      "category": "技术优势",
      "question": "相比传统的纯LLM方案，RAG技术有哪些优势？",
      "ground_truth": "RAG技术相比纯LLM方案的优势包括：1）准确性更高：基于实际文档生成答案，减少幻觉；2）可追溯性：每个答案都能追溯到具体的信息源；3）知识更新灵活：无需重新训练模型即可更新知识库；4）成本效益：不需要超大模型也能处理专业领域问题；5）隐私保护：敏感数据可以保存在本地知识库中。",
      "expected_keywords": ["准确性", "可追溯", "知识更新", "成本", "隐私", "幻觉"],
      "difficulty": "medium"
    },
    {
      "id": "tc_004",
      "category": "检索策略",
      "question": "什么是混合检索？它如何提升RAG系统的性能？",
      "ground_truth": "混合检索是指同时使用多种检索方法的策略，最常见的是结合向量检索（语义搜索）和关键词检索（如BM25）。向量检索擅长捕捉语义相似性，而关键词检索在精确匹配方面表现更好。通过加权融合或倒数排名融合（RRF）等方法结合两者的结果，可以同时获得语义理解和精确匹配的优势，从而提升整体检索效果。",
      "expected_keywords": ["向量检索", "关键词检索", "BM25", "语义", "加权融合", "RRF"],
      "difficulty": "hard"
    },
    {
      "id": "tc_005",
      "category": "分块策略",
      "question": "在RAG系统中，如何确定最佳的文档分块大小？",
      "ground_truth": "确定最佳分块大小需要平衡多个因素：1）上下文完整性：块太小会丢失上下文，太大会包含无关信息；2）模型限制：考虑嵌入模型和LLM的token限制；3）检索精度：较小的块通常有更高的检索精度；4）文档类型：技术文档可能需要更大的块，而FAQ可以用较小的块。通常建议从512-1024 tokens开始，通过实验优化。同时可以使用重叠分块和层级分块等高级策略。",
      "expected_keywords": ["上下文", "token限制", "检索精度", "文档类型", "重叠", "层级"],
      "difficulty": "hard"
    },
    {
      "id": "tc_006",
      "category": "性能评估",
      "question": "如何评估RAG系统的性能？有哪些关键指标？",
      "ground_truth": "RAG系统的性能评估包括多个维度：1）忠实度（Faithfulness）：答案是否基于检索的内容；2）答案相关性：答案是否回答了用户的问题；3）上下文精确度：检索的文档是否相关；4）上下文召回率：相关信息是否都被检索到；5）答案正确性：与标准答案的匹配度；6）响应时间：系统的延迟表现。可以使用Ragas等框架进行自动化评估。",
      "expected_keywords": ["忠实度", "相关性", "精确度", "召回率", "正确性", "响应时间", "Ragas"],
      "difficulty": "medium"
    },
    {
      "id": "tc_007",
      "category": "优化技术",
      "question": "什么是查询扩展？它如何改善RAG系统的检索效果？",
      "ground_truth": "查询扩展是一种通过生成多个相关查询来提高检索召回率的技术。具体方法包括：1）同义词扩展：添加查询词的同义词；2）LLM生成：使用语言模型生成相关的查询变体；3）历史查询：利用用户的查询历史。通过扩展查询，系统可以从不同角度检索相关文档，捕获那些可能被单一查询遗漏的相关信息，从而提高检索的全面性。",
      "expected_keywords": ["同义词", "查询变体", "召回率", "多角度", "全面性"],
      "difficulty": "medium"
    },
    {
      "id": "tc_008",
      "category": "实现细节",
      "question": "在实现RAG系统时，如何处理多语言文档？",
      "ground_truth": "处理多语言文档的策略包括：1）使用多语言嵌入模型（如multilingual-e5）进行统一向量化；2）在检索时进行语言检测和查询翻译；3）为不同语言建立独立的索引并行检索；4）使用跨语言的重排序模型；5）在生成阶段指定输出语言。关键是选择支持目标语言的模型，并在整个流程中保持语言一致性的处理。",
      "expected_keywords": ["多语言嵌入", "语言检测", "查询翻译", "独立索引", "跨语言", "一致性"],
      "difficulty": "hard"
    },
    {
      "id": "tc_009",
      "category": "应用场景",
      "question": "RAG技术适合哪些应用场景？请举例说明。",
      "ground_truth": "RAG技术适合的应用场景包括：1）企业知识库问答：基于内部文档回答员工问题；2）客户支持系统：根据产品文档和FAQ提供准确答案；3）法律文书分析：从法律条文中检索相关内容；4）医疗咨询助手：基于医学文献提供专业建议；5）教育辅导系统：从教材中提取知识点解答问题；6）代码文档查询：帮助开发者理解API和框架。这些场景的共同特点是需要基于特定领域的文档提供准确、可信的答案。",
      "expected_keywords": ["企业知识库", "客户支持", "法律", "医疗", "教育", "代码文档", "领域", "可信"],
      "difficulty": "easy"
    },
    {
      "id": "tc_010",
      "category": "挑战与解决",
      "question": "RAG系统面临的主要挑战有哪些？如何解决？",
      "ground_truth": "RAG系统的主要挑战及解决方案：1）检索质量问题：使用混合检索、查询扩展和重排序提升；2）上下文窗口限制：通过智能截断和分块优化；3）信息冲突：实现来源可信度评分和时间戳管理；4）实时性要求：使用缓存和向量数据库优化；5）多模态内容：集成OCR和多模态嵌入模型；6）成本控制：选择合适的模型规模和批处理策略。关键是根据具体场景进行针对性优化。",
      "expected_keywords": ["检索质量", "上下文限制", "信息冲突", "实时性", "多模态", "成本", "优化"],
      "difficulty": "hard"
    }
  ]
}